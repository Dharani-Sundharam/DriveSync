# ü§ñ Robot Control System - Mermaid Diagrams

## System Architecture Diagram

```mermaid
graph TB
    %% User Interface Layer
    subgraph UI ["üñ•Ô∏è USER INTERFACE LAYER"]
        GUI[Main GUI<br/>Auto-Resolution Display<br/>‚Ä¢ Map Visualization<br/>‚Ä¢ Robot Position<br/>‚Ä¢ Path Display]
        LIDAR_UI[LIDAR Overlay<br/>480x320 Cartesian Plot<br/>‚Ä¢ Real-time Scan<br/>‚Ä¢ Occupancy Grid<br/>‚Ä¢ Obstacle Points]
        CONTROL[Control Panel<br/>Manual/Auto Modes<br/>‚Ä¢ Target Setting<br/>‚Ä¢ Safety Status<br/>‚Ä¢ System Stats]
    end

    %% Control & Coordination Layer
    subgraph COORD ["üéõÔ∏è CONTROL & COORDINATION LAYER"]
        MAIN[PathfindingRobotController<br/>Main Orchestrator<br/>‚Ä¢ System Integration<br/>‚Ä¢ Event Handling<br/>‚Ä¢ Safety Management]
        LIDAR_ENH[LIDAR Enhanced Controller<br/>‚Ä¢ LIDAR Data Fusion<br/>‚Ä¢ Obstacle Detection<br/>‚Ä¢ Enhanced Navigation]
        SAFETY_MGR[Safety Manager<br/>‚Ä¢ Collision Avoidance<br/>‚Ä¢ Emergency Stop<br/>‚Ä¢ Multi-sensor Fusion]
    end

    %% Algorithm & Processing Layer
    subgraph ALGO ["üß† ALGORITHM & PROCESSING LAYER"]
        MAP_ENV[Map Environment<br/>‚Ä¢ Road Network<br/>‚Ä¢ Boundaries<br/>‚Ä¢ Obstacles<br/>‚Ä¢ Coordinate System]
        PATHFIND[Pathfinding Algorithms<br/>‚Ä¢ A* Algorithm<br/>‚Ä¢ RRT Algorithm<br/>‚Ä¢ Road Snapping<br/>‚Ä¢ Path Optimization]
        NAV_CTRL[Navigation Controller<br/>‚Ä¢ PID Control<br/>‚Ä¢ Path Following<br/>‚Ä¢ Waypoint Navigation<br/>‚Ä¢ Speed Control]
        LIDAR_MAP[LIDAR Mapping<br/>‚Ä¢ Scan Processing<br/>‚Ä¢ Occupancy Grid<br/>‚Ä¢ Real-time Mapping<br/>‚Ä¢ Obstacle Detection]
        COLLISION[Collision Avoidance<br/>‚Ä¢ YOLO Detection<br/>‚Ä¢ Safety States<br/>‚Ä¢ Emergency Response<br/>‚Ä¢ Object Classification]
        KINEMATICS[Robot Kinematics<br/>‚Ä¢ Differential Drive<br/>‚Ä¢ Encoder Processing<br/>‚Ä¢ Position Calculation<br/>‚Ä¢ Motion Planning]
    end

    %% Hardware Abstraction Layer
    subgraph HAL ["üîå HARDWARE ABSTRACTION LAYER"]
        ROBOT_CTRL[Robot Controller<br/>‚Ä¢ Serial Communication<br/>‚Ä¢ Encoder Data<br/>‚Ä¢ Motor Commands<br/>‚Ä¢ Position Tracking]
        LIDAR_IF[LIDAR Interface<br/>‚Ä¢ YDLidar-SDK<br/>‚Ä¢ Scan Data Processing<br/>‚Ä¢ Port Management<br/>‚Ä¢ Configuration]
        CAMERA_IF[Camera Interface<br/>‚Ä¢ OpenCV Integration<br/>‚Ä¢ YOLO Model<br/>‚Ä¢ Real-time Processing<br/>‚Ä¢ Object Detection]
        SERIAL_COMM[Serial Communication<br/>‚Ä¢ Thread-Safe Queues<br/>‚Ä¢ Error Handling<br/>‚Ä¢ Auto Port Detection<br/>‚Ä¢ Protocol Management]
    end

    %% Hardware Layer
    subgraph HW ["‚öôÔ∏è HARDWARE LAYER"]
        RPI[Raspberry Pi 4<br/>‚Ä¢ Main Computer<br/>‚Ä¢ Linux OS<br/>‚Ä¢ Python Runtime<br/>‚Ä¢ Display Output]
        LIDAR_HW[YDLIDAR X2<br/>‚Ä¢ 360¬∞ Laser Scanner<br/>‚Ä¢ 8m Range<br/>‚Ä¢ 6-12Hz Scan Rate<br/>‚Ä¢ USB Interface]
        CAMERA_HW[USB Camera<br/>‚Ä¢ Video Stream<br/>‚Ä¢ Object Detection<br/>‚Ä¢ Safety Monitoring<br/>‚Ä¢ CV Processing]
        ARDUINO[Arduino Uno<br/>‚Ä¢ Motor Driver<br/>‚Ä¢ Encoder Reading<br/>‚Ä¢ Real-time Control<br/>‚Ä¢ PWM Generation]
        CHASSIS[Differential Drive<br/>‚Ä¢ 210mm Length<br/>‚Ä¢ 70mm Wheels<br/>‚Ä¢ 200mm Wheelbase<br/>‚Ä¢ Encoder Feedback]
        MOTORS[DC Motors & Encoders<br/>‚Ä¢ Left: 4993 ticks/rev<br/>‚Ä¢ Right: 4966 ticks/rev<br/>‚Ä¢ L298N Driver<br/>‚Ä¢ PWM Control]
        POWER[Power System<br/>‚Ä¢ 12V Motor Supply<br/>‚Ä¢ 5V Electronics<br/>‚Ä¢ Battery Management<br/>‚Ä¢ Power Monitoring]
    end

    %% Connections
    UI --> COORD
    COORD --> ALGO
    ALGO --> HAL
    HAL --> HW

    %% Detailed connections
    MAIN --> LIDAR_ENH
    MAIN --> SAFETY_MGR
    LIDAR_ENH --> LIDAR_MAP
    SAFETY_MGR --> COLLISION
    MAP_ENV --> PATHFIND
    PATHFIND --> NAV_CTRL
    NAV_CTRL --> KINEMATICS
    ROBOT_CTRL --> ARDUINO
    LIDAR_IF --> LIDAR_HW
    CAMERA_IF --> CAMERA_HW
    SERIAL_COMM --> ARDUINO

    %% Styling
    classDef uiLayer fill:#3b82f6,stroke:#1e40af,stroke-width:2px,color:#fff
    classDef coordLayer fill:#10b981,stroke:#047857,stroke-width:2px,color:#fff
    classDef algoLayer fill:#f59e0b,stroke:#d97706,stroke-width:2px,color:#fff
    classDef halLayer fill:#8b5cf6,stroke:#7c3aed,stroke-width:2px,color:#fff
    classDef hwLayer fill:#ef4444,stroke:#dc2626,stroke-width:2px,color:#fff

    class GUI,LIDAR_UI,CONTROL uiLayer
    class MAIN,LIDAR_ENH,SAFETY_MGR coordLayer
    class MAP_ENV,PATHFIND,NAV_CTRL,LIDAR_MAP,COLLISION,KINEMATICS algoLayer
    class ROBOT_CTRL,LIDAR_IF,CAMERA_IF,SERIAL_COMM halLayer
    class RPI,LIDAR_HW,CAMERA_HW,ARDUINO,CHASSIS,MOTORS,POWER hwLayer
```

## Data Flow Diagram

```mermaid
flowchart TD
    %% Input Sources
    USER_INPUT[üë§ User Input<br/>‚Ä¢ Mouse Clicks<br/>‚Ä¢ Keyboard Commands<br/>‚Ä¢ Mode Selection]
    LIDAR_SENSOR[üì° LIDAR Sensor<br/>‚Ä¢ 360¬∞ Scans<br/>‚Ä¢ Distance Data<br/>‚Ä¢ Point Cloud]
    CAMERA_SENSOR[üì∑ Camera Sensor<br/>‚Ä¢ Video Stream<br/>‚Ä¢ Object Detection<br/>‚Ä¢ Safety Monitoring]
    ENCODER_FB[‚öôÔ∏è Encoder Feedback<br/>‚Ä¢ Position Data<br/>‚Ä¢ Velocity Info<br/>‚Ä¢ Odometry]

    %% Data Fusion
    subgraph FUSION ["üîÑ SENSOR DATA FUSION"]
        EVENT_PROC[Event Processing<br/>‚Ä¢ User Commands<br/>‚Ä¢ Target Selection<br/>‚Ä¢ Mode Changes]
        LIDAR_PROC[LIDAR Processing<br/>‚Ä¢ Scan Analysis<br/>‚Ä¢ Mapping<br/>‚Ä¢ Obstacle Detection]
        VISION_PROC[Vision Processing<br/>‚Ä¢ Object Detection<br/>‚Ä¢ Classification<br/>‚Ä¢ Safety Assessment]
        ODOM_PROC[Odometry Processing<br/>‚Ä¢ Position Calculation<br/>‚Ä¢ Velocity Estimation<br/>‚Ä¢ State Update]
    end

    %% Decision Making
    subgraph DECISION ["üß† DECISION MAKING"]
        PATH_PLAN[Path Planning<br/>‚Ä¢ A* Algorithm<br/>‚Ä¢ RRT Planning<br/>‚Ä¢ Route Optimization]
        NAV_CONTROL[Navigation Control<br/>‚Ä¢ PID Controller<br/>‚Ä¢ Waypoint Following<br/>‚Ä¢ Speed Regulation]
        SAFETY_CHECK[Safety Assessment<br/>‚Ä¢ Collision Detection<br/>‚Ä¢ Emergency Stop<br/>‚Ä¢ Risk Analysis]
        MODE_MGR[Mode Management<br/>‚Ä¢ Auto/Manual Switch<br/>‚Ä¢ Priority Handling<br/>‚Ä¢ State Machine]
    end

    %% Control Output
    subgraph OUTPUT ["üì§ CONTROL OUTPUT"]
        MOTOR_CMD[Motor Commands<br/>‚Ä¢ Left/Right PWM<br/>‚Ä¢ Direction Control<br/>‚Ä¢ Speed Adjustment]
        DISPLAY_UPD[Display Updates<br/>‚Ä¢ Map Rendering<br/>‚Ä¢ Robot Position<br/>‚Ä¢ Status Info]
        STATUS_IND[Status Indicators<br/>‚Ä¢ Safety Status<br/>‚Ä¢ Navigation State<br/>‚Ä¢ System Health]
        DATA_LOG[Data Logging<br/>‚Ä¢ Telemetry<br/>‚Ä¢ Debug Info<br/>‚Ä¢ Performance Metrics]
    end

    %% Hardware Execution
    MOTORS[üîß Motor Hardware<br/>‚Ä¢ Physical Movement<br/>‚Ä¢ Encoder Feedback]
    DISPLAY[üñ•Ô∏è Display Hardware<br/>‚Ä¢ GUI Rendering<br/>‚Ä¢ Visual Feedback]
    STORAGE[üíæ File System<br/>‚Ä¢ Log Storage<br/>‚Ä¢ Map Persistence]

    %% Flow Connections
    USER_INPUT --> EVENT_PROC
    LIDAR_SENSOR --> LIDAR_PROC
    CAMERA_SENSOR --> VISION_PROC
    ENCODER_FB --> ODOM_PROC

    EVENT_PROC --> PATH_PLAN
    LIDAR_PROC --> SAFETY_CHECK
    LIDAR_PROC --> PATH_PLAN
    VISION_PROC --> SAFETY_CHECK
    ODOM_PROC --> NAV_CONTROL

    PATH_PLAN --> NAV_CONTROL
    NAV_CONTROL --> MOTOR_CMD
    SAFETY_CHECK --> MODE_MGR
    MODE_MGR --> MOTOR_CMD
    MODE_MGR --> DISPLAY_UPD

    MOTOR_CMD --> MOTORS
    DISPLAY_UPD --> DISPLAY
    STATUS_IND --> DISPLAY
    DATA_LOG --> STORAGE

    %% Feedback Loop
    MOTORS --> ENCODER_FB

    %% Styling
    classDef inputStyle fill:#e0f2fe,stroke:#0277bd,stroke-width:2px
    classDef processStyle fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    classDef decisionStyle fill:#fff3e0,stroke:#ef6c00,stroke-width:2px
    classDef outputStyle fill:#e8f5e8,stroke:#2e7d32,stroke-width:2px
    classDef hardwareStyle fill:#ffebee,stroke:#c62828,stroke-width:2px

    class USER_INPUT,LIDAR_SENSOR,CAMERA_SENSOR,ENCODER_FB inputStyle
    class EVENT_PROC,LIDAR_PROC,VISION_PROC,ODOM_PROC processStyle
    class PATH_PLAN,NAV_CONTROL,SAFETY_CHECK,MODE_MGR decisionStyle
    class MOTOR_CMD,DISPLAY_UPD,STATUS_IND,DATA_LOG outputStyle
    class MOTORS,DISPLAY,STORAGE hardwareStyle
```

## Control Loop Diagram

```mermaid
flowchart LR
    subgraph LOOP ["üîÑ MAIN CONTROL LOOP (20 Hz - 50ms Cycle)"]
        COLLECT[üìä Data Collection<br/>‚Ä¢ LIDAR Scanning<br/>‚Ä¢ Camera Monitoring<br/>‚Ä¢ Encoder Reading<br/>‚Ä¢ User Input]
        
        PROCESS[‚ö° Processing<br/>‚Ä¢ LIDAR Mapping<br/>‚Ä¢ Object Detection<br/>‚Ä¢ Position Calculation<br/>‚Ä¢ Safety Assessment]
        
        DECIDE[üéØ Decision Making<br/>‚Ä¢ Path Planning<br/>‚Ä¢ Navigation Control<br/>‚Ä¢ Safety Override<br/>‚Ä¢ Mode Management]
        
        EXECUTE[üöÄ Execution<br/>‚Ä¢ Motor Commands<br/>‚Ä¢ Display Updates<br/>‚Ä¢ Status Communication<br/>‚Ä¢ Data Logging]
    end

    %% Loop connections
    COLLECT --> PROCESS
    PROCESS --> DECIDE
    DECIDE --> EXECUTE
    EXECUTE --> COLLECT

    %% External connections
    SENSORS[üîç Sensors<br/>LIDAR + Camera + Encoders]
    ACTUATORS[‚öôÔ∏è Actuators<br/>Motors + Display + Storage]

    SENSORS --> COLLECT
    EXECUTE --> ACTUATORS
    ACTUATORS -.->|Feedback| COLLECT

    %% Timing annotations
    COLLECT -.->|12.5ms| PROCESS
    PROCESS -.->|12.5ms| DECIDE
    DECIDE -.->|12.5ms| EXECUTE
    EXECUTE -.->|12.5ms| COLLECT

    %% Styling
    classDef loopStyle fill:#e3f2fd,stroke:#1976d2,stroke-width:3px,color:#000
    classDef externalStyle fill:#f1f8e9,stroke:#388e3c,stroke-width:2px,color:#000

    class COLLECT,PROCESS,DECIDE,EXECUTE loopStyle
    class SENSORS,ACTUATORS externalStyle
```

## Safety System Architecture

```mermaid
flowchart TD
    subgraph SAFETY ["üõ°Ô∏è MULTI-LAYER SAFETY SYSTEM"]
        subgraph LAYER1 ["Layer 1: Predictive Safety"]
            LIDAR_OBS[LIDAR Obstacle Detection<br/>‚Ä¢ 360¬∞ Awareness<br/>‚Ä¢ 8m Range<br/>‚Ä¢ Real-time Mapping]
            PATH_CHECK[Path Clearance Check<br/>‚Ä¢ Occupancy Grid<br/>‚Ä¢ Route Validation<br/>‚Ä¢ Proactive Avoidance]
        end

        subgraph LAYER2 ["Layer 2: Reactive Safety"]
            YOLO_DET[YOLO Object Detection<br/>‚Ä¢ Real-time ID<br/>‚Ä¢ Critical Objects<br/>‚Ä¢ Confidence Scoring]
            EMERGENCY[Emergency Stop System<br/>‚Ä¢ <100ms Response<br/>‚Ä¢ Motor Cutoff<br/>‚Ä¢ Safety State]
        end

        subgraph LAYER3 ["Layer 3: Manual Override"]
            USER_CTRL[User Control<br/>‚Ä¢ Manual Override<br/>‚Ä¢ Instant Takeover<br/>‚Ä¢ Safety Priority]
            STATE_MGR[Safety State Manager<br/>‚Ä¢ Risk Assessment<br/>‚Ä¢ Graduated Response<br/>‚Ä¢ Recovery Logic]
        end
    end

    %% Safety flow
    ENVIRONMENT[üåç Environment]
    ROBOT[ü§ñ Robot]

    ENVIRONMENT --> LIDAR_OBS
    ENVIRONMENT --> YOLO_DET
    
    LIDAR_OBS --> PATH_CHECK
    YOLO_DET --> EMERGENCY
    PATH_CHECK --> STATE_MGR
    EMERGENCY --> STATE_MGR
    USER_CTRL --> STATE_MGR
    
    STATE_MGR --> ROBOT

    %% Safety responses
    ROBOT -.->|Safe Operation| ENVIRONMENT
    STATE_MGR -.->|Emergency Stop| ROBOT
    STATE_MGR -.->|Slow Down| ROBOT
    STATE_MGR -.->|Change Path| ROBOT

    %% Styling
    classDef layer1Style fill:#c8e6c9,stroke:#4caf50,stroke-width:2px
    classDef layer2Style fill:#ffecb3,stroke:#ff9800,stroke-width:2px
    classDef layer3Style fill:#ffcdd2,stroke:#f44336,stroke-width:2px
    classDef systemStyle fill:#e1bee7,stroke:#9c27b0,stroke-width:2px

    class LIDAR_OBS,PATH_CHECK layer1Style
    class YOLO_DET,EMERGENCY layer2Style
    class USER_CTRL,STATE_MGR layer3Style
    class ENVIRONMENT,ROBOT systemStyle
```

## Communication Architecture

```mermaid
flowchart LR
    subgraph SYSTEM ["üñ•Ô∏è RASPBERRY PI SYSTEM"]
        MAIN_APP[Main Application<br/>PathfindingRobotController]
        LIDAR_APP[LIDAR Application<br/>YDLidar Interface]
        CAMERA_APP[Camera Application<br/>YOLO Detection]
    end

    subgraph COMM ["üì° COMMUNICATION LAYER"]
        USB0[USB0 Serial<br/>/dev/ttyUSB0<br/>115200 baud]
        USB1[USB1 Serial<br/>/dev/ttyUSB1<br/>115200 baud]
        USB_CAM[USB Camera<br/>/dev/video0<br/>Video Stream]
    end

    subgraph HARDWARE ["‚öôÔ∏è HARDWARE DEVICES"]
        ARDUINO[Arduino Uno<br/>‚Ä¢ Motor Control<br/>‚Ä¢ Encoder Reading<br/>‚Ä¢ Real-time Response]
        LIDAR_DEV[YDLIDAR X2<br/>‚Ä¢ 360¬∞ Scanning<br/>‚Ä¢ Distance Measurement<br/>‚Ä¢ Point Cloud Data]
        CAMERA_DEV[USB Camera<br/>‚Ä¢ Video Capture<br/>‚Ä¢ Object Detection<br/>‚Ä¢ Safety Monitoring]
    end

    %% Communication paths
    MAIN_APP <--> USB0
    LIDAR_APP <--> USB1
    CAMERA_APP <--> USB_CAM

    USB0 <--> ARDUINO
    USB1 <--> LIDAR_DEV
    USB_CAM <--> CAMERA_DEV

    %% Data types
    USB0 -.->|Motor Commands<br/>Encoder Data| ARDUINO
    USB1 -.->|Scan Data<br/>Configuration| LIDAR_DEV
    USB_CAM -.->|Video Frames<br/>Detection Results| CAMERA_DEV

    %% Styling
    classDef appStyle fill:#bbdefb,stroke:#1976d2,stroke-width:2px
    classDef commStyle fill:#c8e6c9,stroke:#388e3c,stroke-width:2px
    classDef hwStyle fill:#ffcdd2,stroke:#d32f2f,stroke-width:2px

    class MAIN_APP,LIDAR_APP,CAMERA_APP appStyle
    class USB0,USB1,USB_CAM commStyle
    class ARDUINO,LIDAR_DEV,CAMERA_DEV hwStyle
```
