# ­Ъцќ Robot Control System - Mermaid Diagrams

## System Architecture Diagram

```mermaid
graph TB
    %% User Interface Layer
    subgraph UI ["­ЪќЦ№ИЈ USER INTERFACE LAYER"]
        GUI[Main GUI<br/>Auto-Resolution Display<br/>Рђб Map Visualization<br/>Рђб Robot Position<br/>Рђб Path Display]
        LIDAR_UI[LIDAR Overlay<br/>480x320 Cartesian Plot<br/>Рђб Real-time Scan<br/>Рђб Occupancy Grid<br/>Рђб Obstacle Points]
        CONTROL[Control Panel<br/>Manual/Auto Modes<br/>Рђб Target Setting<br/>Рђб Safety Status<br/>Рђб System Stats]
    end

    %% Control & Coordination Layer
    subgraph COORD ["­ЪјЏ№ИЈ CONTROL & COORDINATION LAYER"]
        MAIN[PathfindingRobotController<br/>Main Orchestrator<br/>Рђб System Integration<br/>Рђб Event Handling<br/>Рђб Safety Management]
        LIDAR_ENH[LIDAR Enhanced Controller<br/>Рђб LIDAR Data Fusion<br/>Рђб Obstacle Detection<br/>Рђб Enhanced Navigation]
        SAFETY_MGR[Safety Manager<br/>Рђб Collision Avoidance<br/>Рђб Emergency Stop<br/>Рђб Multi-sensor Fusion]
    end

    %% Algorithm & Processing Layer
    subgraph ALGO ["­ЪДа ALGORITHM & PROCESSING LAYER"]
        MAP_ENV[Map Environment<br/>Рђб Road Network<br/>Рђб Boundaries<br/>Рђб Obstacles<br/>Рђб Coordinate System]
        PATHFIND[Pathfinding Algorithms<br/>Рђб A* Algorithm<br/>Рђб RRT Algorithm<br/>Рђб Road Snapping<br/>Рђб Path Optimization]
        NAV_CTRL[Navigation Controller<br/>Рђб PID Control<br/>Рђб Path Following<br/>Рђб Waypoint Navigation<br/>Рђб Speed Control]
        LIDAR_MAP[LIDAR Mapping<br/>Рђб Scan Processing<br/>Рђб Occupancy Grid<br/>Рђб Real-time Mapping<br/>Рђб Obstacle Detection]
        COLLISION[Collision Avoidance<br/>Рђб YOLO Detection<br/>Рђб Safety States<br/>Рђб Emergency Response<br/>Рђб Object Classification]
        KINEMATICS[Robot Kinematics<br/>Рђб Differential Drive<br/>Рђб Encoder Processing<br/>Рђб Position Calculation<br/>Рђб Motion Planning]
    end

    %% Hardware Abstraction Layer
    subgraph HAL ["­Ъћї HARDWARE ABSTRACTION LAYER"]
        ROBOT_CTRL[Robot Controller<br/>Рђб Serial Communication<br/>Рђб Encoder Data<br/>Рђб Motor Commands<br/>Рђб Position Tracking]
        LIDAR_IF[LIDAR Interface<br/>Рђб YDLidar-SDK<br/>Рђб Scan Data Processing<br/>Рђб Port Management<br/>Рђб Configuration]
        CAMERA_IF[Camera Interface<br/>Рђб OpenCV Integration<br/>Рђб YOLO Model<br/>Рђб Real-time Processing<br/>Рђб Object Detection]
        SERIAL_COMM[Serial Communication<br/>Рђб Thread-Safe Queues<br/>Рђб Error Handling<br/>Рђб Auto Port Detection<br/>Рђб Protocol Management]
    end

    %% Hardware Layer
    subgraph HW ["РџЎ№ИЈ HARDWARE LAYER"]
        RPI[Raspberry Pi 4<br/>Рђб Main Computer<br/>Рђб Linux OS<br/>Рђб Python Runtime<br/>Рђб Display Output]
        LIDAR_HW[YDLIDAR X2<br/>Рђб 360┬░ Laser Scanner<br/>Рђб 8m Range<br/>Рђб 6-12Hz Scan Rate<br/>Рђб USB Interface]
        CAMERA_HW[USB Camera<br/>Рђб Video Stream<br/>Рђб Object Detection<br/>Рђб Safety Monitoring<br/>Рђб CV Processing]
        ARDUINO[Arduino Uno<br/>Рђб Motor Driver<br/>Рђб Encoder Reading<br/>Рђб Real-time Control<br/>Рђб PWM Generation]
        CHASSIS[Differential Drive<br/>Рђб 210mm Length<br/>Рђб 70mm Wheels<br/>Рђб 200mm Wheelbase<br/>Рђб Encoder Feedback]
        MOTORS[DC Motors & Encoders<br/>Рђб Left: 4993 ticks/rev<br/>Рђб Right: 4966 ticks/rev<br/>Рђб L298N Driver<br/>Рђб PWM Control]
        POWER[Power System<br/>Рђб 12V Motor Supply<br/>Рђб 5V Electronics<br/>Рђб Battery Management<br/>Рђб Power Monitoring]
    end

    %% Connections
    UI --> COORD
    COORD --> ALGO
    ALGO --> HAL
    HAL --> HW

    %% Detailed connections
    MAIN --> LIDAR_ENH
    MAIN --> SAFETY_MGR
    LIDAR_ENH --> LIDAR_MAP
    SAFETY_MGR --> COLLISION
    MAP_ENV --> PATHFIND
    PATHFIND --> NAV_CTRL
    NAV_CTRL --> KINEMATICS
    ROBOT_CTRL --> ARDUINO
    LIDAR_IF --> LIDAR_HW
    CAMERA_IF --> CAMERA_HW
    SERIAL_COMM --> ARDUINO

    %% Styling
    classDef uiLayer fill:#3b82f6,stroke:#1e40af,stroke-width:2px,color:#fff
    classDef coordLayer fill:#10b981,stroke:#047857,stroke-width:2px,color:#fff
    classDef algoLayer fill:#f59e0b,stroke:#d97706,stroke-width:2px,color:#fff
    classDef halLayer fill:#8b5cf6,stroke:#7c3aed,stroke-width:2px,color:#fff
    classDef hwLayer fill:#ef4444,stroke:#dc2626,stroke-width:2px,color:#fff

    class GUI,LIDAR_UI,CONTROL uiLayer
    class MAIN,LIDAR_ENH,SAFETY_MGR coordLayer
    class MAP_ENV,PATHFIND,NAV_CTRL,LIDAR_MAP,COLLISION,KINEMATICS algoLayer
    class ROBOT_CTRL,LIDAR_IF,CAMERA_IF,SERIAL_COMM halLayer
    class RPI,LIDAR_HW,CAMERA_HW,ARDUINO,CHASSIS,MOTORS,POWER hwLayer
```

## Data Flow Diagram

```mermaid
flowchart TD
    %% Input Sources
    USER_INPUT[­ЪЉц User Input<br/>Рђб Mouse Clicks<br/>Рђб Keyboard Commands<br/>Рђб Mode Selection]
    LIDAR_SENSOR[­ЪЊА LIDAR Sensor<br/>Рђб 360┬░ Scans<br/>Рђб Distance Data<br/>Рђб Point Cloud]
    CAMERA_SENSOR[­ЪЊи Camera Sensor<br/>Рђб Video Stream<br/>Рђб Object Detection<br/>Рђб Safety Monitoring]
    ENCODER_FB[РџЎ№ИЈ Encoder Feedback<br/>Рђб Position Data<br/>Рђб Velocity Info<br/>Рђб Odometry]

    %% Data Fusion
    subgraph FUSION ["­Ъћё SENSOR DATA FUSION"]
        EVENT_PROC[Event Processing<br/>Рђб User Commands<br/>Рђб Target Selection<br/>Рђб Mode Changes]
        LIDAR_PROC[LIDAR Processing<br/>Рђб Scan Analysis<br/>Рђб Mapping<br/>Рђб Obstacle Detection]
        VISION_PROC[Vision Processing<br/>Рђб Object Detection<br/>Рђб Classification<br/>Рђб Safety Assessment]
        ODOM_PROC[Odometry Processing<br/>Рђб Position Calculation<br/>Рђб Velocity Estimation<br/>Рђб State Update]
    end

    %% Decision Making
    subgraph DECISION ["­ЪДа DECISION MAKING"]
        PATH_PLAN[Path Planning<br/>Рђб A* Algorithm<br/>Рђб RRT Planning<br/>Рђб Route Optimization]
        NAV_CONTROL[Navigation Control<br/>Рђб PID Controller<br/>Рђб Waypoint Following<br/>Рђб Speed Regulation]
        SAFETY_CHECK[Safety Assessment<br/>Рђб Collision Detection<br/>Рђб Emergency Stop<br/>Рђб Risk Analysis]
        MODE_MGR[Mode Management<br/>Рђб Auto/Manual Switch<br/>Рђб Priority Handling<br/>Рђб State Machine]
    end

    %% Control Output
    subgraph OUTPUT ["­ЪЊц CONTROL OUTPUT"]
        MOTOR_CMD[Motor Commands<br/>Рђб Left/Right PWM<br/>Рђб Direction Control<br/>Рђб Speed Adjustment]
        DISPLAY_UPD[Display Updates<br/>Рђб Map Rendering<br/>Рђб Robot Position<br/>Рђб Status Info]
        STATUS_IND[Status Indicators<br/>Рђб Safety Status<br/>Рђб Navigation State<br/>Рђб System Health]
        DATA_LOG[Data Logging<br/>Рђб Telemetry<br/>Рђб Debug Info<br/>Рђб Performance Metrics]
    end

    %% Hardware Execution
    MOTORS[­ЪћД Motor Hardware<br/>Рђб Physical Movement<br/>Рђб Encoder Feedback]
    DISPLAY[­ЪќЦ№ИЈ Display Hardware<br/>Рђб GUI Rendering<br/>Рђб Visual Feedback]
    STORAGE[­ЪњЙ File System<br/>Рђб Log Storage<br/>Рђб Map Persistence]

    %% Flow Connections
    USER_INPUT --> EVENT_PROC
    LIDAR_SENSOR --> LIDAR_PROC
    CAMERA_SENSOR --> VISION_PROC
    ENCODER_FB --> ODOM_PROC

    EVENT_PROC --> PATH_PLAN
    LIDAR_PROC --> SAFETY_CHECK
    LIDAR_PROC --> PATH_PLAN
    VISION_PROC --> SAFETY_CHECK
    ODOM_PROC --> NAV_CONTROL

    PATH_PLAN --> NAV_CONTROL
    NAV_CONTROL --> MOTOR_CMD
    SAFETY_CHECK --> MODE_MGR
    MODE_MGR --> MOTOR_CMD
    MODE_MGR --> DISPLAY_UPD

    MOTOR_CMD --> MOTORS
    DISPLAY_UPD --> DISPLAY
    STATUS_IND --> DISPLAY
    DATA_LOG --> STORAGE

    %% Feedback Loop
    MOTORS --> ENCODER_FB

    %% Styling
    classDef inputStyle fill:#e0f2fe,stroke:#0277bd,stroke-width:2px
    classDef processStyle fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    classDef decisionStyle fill:#fff3e0,stroke:#ef6c00,stroke-width:2px
    classDef outputStyle fill:#e8f5e8,stroke:#2e7d32,stroke-width:2px
    classDef hardwareStyle fill:#ffebee,stroke:#c62828,stroke-width:2px

    class USER_INPUT,LIDAR_SENSOR,CAMERA_SENSOR,ENCODER_FB inputStyle
    class EVENT_PROC,LIDAR_PROC,VISION_PROC,ODOM_PROC processStyle
    class PATH_PLAN,NAV_CONTROL,SAFETY_CHECK,MODE_MGR decisionStyle
    class MOTOR_CMD,DISPLAY_UPD,STATUS_IND,DATA_LOG outputStyle
    class MOTORS,DISPLAY,STORAGE hardwareStyle
```

## Control Loop Diagram

```mermaid
flowchart LR
    subgraph LOOP ["­Ъћё MAIN CONTROL LOOP (20 Hz - 50ms Cycle)"]
        COLLECT[­ЪЊі Data Collection<br/>Рђб LIDAR Scanning<br/>Рђб Camera Monitoring<br/>Рђб Encoder Reading<br/>Рђб User Input]
        
        PROCESS[РџА Processing<br/>Рђб LIDAR Mapping<br/>Рђб Object Detection<br/>Рђб Position Calculation<br/>Рђб Safety Assessment]
        
        DECIDE[­Ъј» Decision Making<br/>Рђб Path Planning<br/>Рђб Navigation Control<br/>Рђб Safety Override<br/>Рђб Mode Management]
        
        EXECUTE[­Ъџђ Execution<br/>Рђб Motor Commands<br/>Рђб Display Updates<br/>Рђб Status Communication<br/>Рђб Data Logging]
    end

    %% Loop connections
    COLLECT --> PROCESS
    PROCESS --> DECIDE
    DECIDE --> EXECUTE
    EXECUTE --> COLLECT

    %% External connections
    SENSORS[­ЪћЇ Sensors<br/>LIDAR + Camera + Encoders]
    ACTUATORS[РџЎ№ИЈ Actuators<br/>Motors + Display + Storage]

    SENSORS --> COLLECT
    EXECUTE --> ACTUATORS
    ACTUATORS -.->|Feedback| COLLECT

    %% Timing annotations
    COLLECT -.->|12.5ms| PROCESS
    PROCESS -.->|12.5ms| DECIDE
    DECIDE -.->|12.5ms| EXECUTE
    EXECUTE -.->|12.5ms| COLLECT

    %% Styling
    classDef loopStyle fill:#e3f2fd,stroke:#1976d2,stroke-width:3px,color:#000
    classDef externalStyle fill:#f1f8e9,stroke:#388e3c,stroke-width:2px,color:#000

    class COLLECT,PROCESS,DECIDE,EXECUTE loopStyle
    class SENSORS,ACTUATORS externalStyle
```

## Safety System Architecture

```mermaid
flowchart TD
    subgraph SAFETY ["­ЪЏА№ИЈ MULTI-LAYER SAFETY SYSTEM"]
        subgraph LAYER1 ["Layer 1: Predictive Safety"]
            LIDAR_OBS[LIDAR Obstacle Detection<br/>Рђб 360┬░ Awareness<br/>Рђб 8m Range<br/>Рђб Real-time Mapping]
            PATH_CHECK[Path Clearance Check<br/>Рђб Occupancy Grid<br/>Рђб Route Validation<br/>Рђб Proactive Avoidance]
        end

        subgraph LAYER2 ["Layer 2: Reactive Safety"]
            YOLO_DET[YOLO Object Detection<br/>Рђб Real-time ID<br/>Рђб Critical Objects<br/>Рђб Confidence Scoring]
            EMERGENCY[Emergency Stop System<br/>Рђб <100ms Response<br/>Рђб Motor Cutoff<br/>Рђб Safety State]
        end

        subgraph LAYER3 ["Layer 3: Manual Override"]
            USER_CTRL[User Control<br/>Рђб Manual Override<br/>Рђб Instant Takeover<br/>Рђб Safety Priority]
            STATE_MGR[Safety State Manager<br/>Рђб Risk Assessment<br/>Рђб Graduated Response<br/>Рђб Recovery Logic]
        end
    end

    %% Safety flow
    ENVIRONMENT[­ЪїЇ Environment]
    ROBOT[­Ъцќ Robot]

    ENVIRONMENT --> LIDAR_OBS
    ENVIRONMENT --> YOLO_DET
    
    LIDAR_OBS --> PATH_CHECK
    YOLO_DET --> EMERGENCY
    PATH_CHECK --> STATE_MGR
    EMERGENCY --> STATE_MGR
    USER_CTRL --> STATE_MGR
    
    STATE_MGR --> ROBOT

    %% Safety responses
    ROBOT -.->|Safe Operation| ENVIRONMENT
    STATE_MGR -.->|Emergency Stop| ROBOT
    STATE_MGR -.->|Slow Down| ROBOT
    STATE_MGR -.->|Change Path| ROBOT

    %% Styling
    classDef layer1Style fill:#c8e6c9,stroke:#4caf50,stroke-width:2px
    classDef layer2Style fill:#ffecb3,stroke:#ff9800,stroke-width:2px
    classDef layer3Style fill:#ffcdd2,stroke:#f44336,stroke-width:2px
    classDef systemStyle fill:#e1bee7,stroke:#9c27b0,stroke-width:2px

    class LIDAR_OBS,PATH_CHECK layer1Style
    class YOLO_DET,EMERGENCY layer2Style
    class USER_CTRL,STATE_MGR layer3Style
    class ENVIRONMENT,ROBOT systemStyle
```

## Communication Architecture

```mermaid
flowchart LR
    subgraph SYSTEM ["­ЪќЦ№ИЈ RASPBERRY PI SYSTEM"]
        MAIN_APP[Main Application<br/>PathfindingRobotController]
        LIDAR_APP[LIDAR Application<br/>YDLidar Interface]
        CAMERA_APP[Camera Application<br/>YOLO Detection]
    end

    subgraph COMM ["­ЪЊА COMMUNICATION LAYER"]
        USB0[USB0 Serial<br/>/dev/ttyUSB0<br/>115200 baud]
        USB1[USB1 Serial<br/>/dev/ttyUSB1<br/>115200 baud]
        USB_CAM[USB Camera<br/>/dev/video0<br/>Video Stream]
    end

    subgraph HARDWARE ["РџЎ№ИЈ HARDWARE DEVICES"]
        ARDUINO[Arduino Uno<br/>Рђб Motor Control<br/>Рђб Encoder Reading<br/>Рђб Real-time Response]
        LIDAR_DEV[YDLIDAR X2<br/>Рђб 360┬░ Scanning<br/>Рђб Distance Measurement<br/>Рђб Point Cloud Data]
        CAMERA_DEV[USB Camera<br/>Рђб Video Capture<br/>Рђб Object Detection<br/>Рђб Safety Monitoring]
    end

    %% Communication paths
    MAIN_APP <--> USB0
    LIDAR_APP <--> USB1
    CAMERA_APP <--> USB_CAM

    USB0 <--> ARDUINO
    USB1 <--> LIDAR_DEV
    USB_CAM <--> CAMERA_DEV

    %% Data types
    USB0 -.->|Motor Commands<br/>Encoder Data| ARDUINO
    USB1 -.->|Scan Data<br/>Configuration| LIDAR_DEV
    USB_CAM -.->|Video Frames<br/>Detection Results| CAMERA_DEV

    %% Styling
    classDef appStyle fill:#bbdefb,stroke:#1976d2,stroke-width:2px
    classDef commStyle fill:#c8e6c9,stroke:#388e3c,stroke-width:2px
    classDef hwStyle fill:#ffcdd2,stroke:#d32f2f,stroke-width:2px

    class MAIN_APP,LIDAR_APP,CAMERA_APP appStyle
    class USB0,USB1,USB_CAM commStyle
    class ARDUINO,LIDAR_DEV,CAMERA_DEV hwStyle
```
